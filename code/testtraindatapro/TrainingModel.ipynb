{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\griff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\griff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\griff\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download ('stopwords')\n",
    "nltk.download ('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date      flag  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              tweet  length  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...      19   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...      21   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...      18   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire       10   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....      21   \n",
       "\n",
       "  token token2 filtered stemmed lemmed  \n",
       "0                                       \n",
       "1                                       \n",
       "2                                       \n",
       "3                                       \n",
       "4                                       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file = \"../../../../tweet-training-data.csv\"\n",
    "file = \"tweet-training-data.csv\"\n",
    "data_df = pd.read_csv(file,encoding = \"latin1\", names=[\"sentiment\",\"id\", \"date\", \"flag\", \"user\",\"tweet\"])\n",
    "# data_df= data_df.replace(to_replace =4, \n",
    "#                  value =1) \n",
    "data_df['length'] = data_df['tweet'].str.split(\" \").str.len()-1\n",
    "data_df['token'] =''\n",
    "data_df['token2'] = ''\n",
    "data_df['filtered']=''\n",
    "data_df['stemmed']=''\n",
    "data_df['lemmed']=''\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 12 columns):\n",
      "sentiment    1600000 non-null int64\n",
      "id           1600000 non-null int64\n",
      "date         1600000 non-null object\n",
      "flag         1600000 non-null object\n",
      "user         1600000 non-null object\n",
      "tweet        1600000 non-null object\n",
      "length       1600000 non-null int64\n",
      "token        1600000 non-null object\n",
      "token2       1600000 non-null object\n",
      "filtered     1600000 non-null object\n",
      "stemmed      1600000 non-null object\n",
      "lemmed       1600000 non-null object\n",
      "dtypes: int64(3), object(9)\n",
      "memory usage: 146.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\griff\\Anaconda3\\envs\\pandas\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download ('stopwords')\n",
    "# nltk.download ('punkt')\n",
    "\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "# for index, row in data_df.head().iterrows():\n",
    "#     tokenized_text=sent_tokenize(row[\"tweet\"])\n",
    "#     data_df.set_value(index, 'token', tokenized_text)\n",
    "    \n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "for index, row in data_df.head().iterrows():\n",
    "    tokenized_word=word_tokenize(row['tweet'])\n",
    "    data_df.set_value(index, 'token2', tokenized_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\griff\\Anaconda3\\envs\\pandas\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "for index, row in data_df.head().iterrows():\n",
    "    filtered_sent=[]\n",
    "    for w in row['token2']:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "        data_df.set_value(index, 'filtered', filtered_sent)\n",
    "#             row['filtered'].update(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\griff\\Anaconda3\\envs\\pandas\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "for index, row in data_df.head().iterrows():\n",
    "    stemmed_words=[]\n",
    "    for w in row['filtered']:\n",
    "        stemmed_words.append(ps.stem(w))\n",
    "    data_df.set_value(index, 'stemmed', stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\griff\\Anaconda3\\envs\\pandas\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "# nltk.download('wordnet')\n",
    "for index, row in data_df.head().iterrows():\n",
    "    lemmed_words=[]\n",
    "    for w in row['stemmed']:\n",
    "        lemmed_words.append(lem.lemmatize(w,\"v\"))\n",
    "    data_df.set_value(index, 'lemmed', lemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['combined'] = data_df.stemmed.astype(str)\n",
    "data_df['combined'] = data_df.combined.str.replace('\\[|\\]|\\,|\\'', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>token</th>\n",
       "      <th>token2</th>\n",
       "      <th>filtered</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmed</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>[@, switchfoot, http, :, //twitpic.com/2y1zl, ...</td>\n",
       "      <td>[@, switchfoot, http, :, //twitpic.com/2y1zl, ...</td>\n",
       "      <td>[@, switchfoot, http, :, //twitpic.com/2y1zl, ...</td>\n",
       "      <td>[@, switchfoot, http, :, //twitpic.com/2y1zl, ...</td>\n",
       "      <td>@ switchfoot http : //twitpic.com/2y1zl - awww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td>[is, upset, that, he, ca, n't, update, his, Fa...</td>\n",
       "      <td>[upset, ca, n't, update, Facebook, texting, .....</td>\n",
       "      <td>[upset, ca, n't, updat, facebook, text, ..., m...</td>\n",
       "      <td>[upset, ca, n't, updat, facebook, text, ..., m...</td>\n",
       "      <td>upset ca \"nt\" updat facebook text ... might cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>18</td>\n",
       "      <td></td>\n",
       "      <td>[@, Kenichan, I, dived, many, times, for, the,...</td>\n",
       "      <td>[@, Kenichan, I, dived, many, times, ball, ., ...</td>\n",
       "      <td>[@, kenichan, I, dive, mani, time, ball, ., ma...</td>\n",
       "      <td>[@, kenichan, I, dive, mani, time, ball, ., ma...</td>\n",
       "      <td>@ kenichan I dive mani time ball . manag save ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "      <td>[whole, bodi, feel, itchi, like, fire]</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td>[@, nationwideclass, no, ,, it, 's, not, behav...</td>\n",
       "      <td>[@, nationwideclass, ,, 's, behaving, ., 'm, m...</td>\n",
       "      <td>[@, nationwideclass, ,, 's, behav, ., 'm, mad,...</td>\n",
       "      <td>[@, nationwideclass, ,, 's, behav, ., 'm, mad,...</td>\n",
       "      <td>@ nationwideclass  \"s\" behav . \"m\" mad . ? I c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date      flag  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                              tweet  length  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...      19   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...      21   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...      18   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire       10   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....      21   \n",
       "\n",
       "  token                                             token2  \\\n",
       "0        [@, switchfoot, http, :, //twitpic.com/2y1zl, ...   \n",
       "1        [is, upset, that, he, ca, n't, update, his, Fa...   \n",
       "2        [@, Kenichan, I, dived, many, times, for, the,...   \n",
       "3        [my, whole, body, feels, itchy, and, like, its...   \n",
       "4        [@, nationwideclass, no, ,, it, 's, not, behav...   \n",
       "\n",
       "                                            filtered  \\\n",
       "0  [@, switchfoot, http, :, //twitpic.com/2y1zl, ...   \n",
       "1  [upset, ca, n't, update, Facebook, texting, .....   \n",
       "2  [@, Kenichan, I, dived, many, times, ball, ., ...   \n",
       "3            [whole, body, feels, itchy, like, fire]   \n",
       "4  [@, nationwideclass, ,, 's, behaving, ., 'm, m...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [@, switchfoot, http, :, //twitpic.com/2y1zl, ...   \n",
       "1  [upset, ca, n't, updat, facebook, text, ..., m...   \n",
       "2  [@, kenichan, I, dive, mani, time, ball, ., ma...   \n",
       "3             [whole, bodi, feel, itchi, like, fire]   \n",
       "4  [@, nationwideclass, ,, 's, behav, ., 'm, mad,...   \n",
       "\n",
       "                                              lemmed  \\\n",
       "0  [@, switchfoot, http, :, //twitpic.com/2y1zl, ...   \n",
       "1  [upset, ca, n't, updat, facebook, text, ..., m...   \n",
       "2  [@, kenichan, I, dive, mani, time, ball, ., ma...   \n",
       "3             [whole, bodi, feel, itchi, like, fire]   \n",
       "4  [@, nationwideclass, ,, 's, behav, ., 'm, mad,...   \n",
       "\n",
       "                                            combined  \n",
       "0  @ switchfoot http : //twitpic.com/2y1zl - awww...  \n",
       "1  upset ca \"nt\" updat facebook text ... might cr...  \n",
       "2  @ kenichan I dive mani time ball . manag save ...  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4  @ nationwideclass  \"s\" behav . \"m\" mad . ? I c...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tf=TfidfVectorizer()\n",
    "# text_tf= tf.fit_transform(row['lemmed'])\n",
    "# text_list.append(text_tf)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(lowercase=False,stop_words='english', ngram_range = (1,1),tokenizer = token.tokenize,max_features=30495)\n",
    "\n",
    "text_counts= cv.fit_transform(data_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600000x30495 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11665531 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-39fb7451f8dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mngram_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtext_counts\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mlist_of_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlist_of_tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1021\u001b[1;33m                 \u001b[1;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m                 \"string object received.\")\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "# # from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# ps = PorterStemmer()\n",
    "\n",
    "# stemmed_words=[]\n",
    "# for w in filtered_sent:\n",
    "#     stemmed_words.append(ps.stem(w))\n",
    "# # from nltk.tokenize import RegexpTokenizer\n",
    "# #tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "# token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "# list_of_tweets = []\n",
    "# for index, row in data_df.iterrows():\n",
    "# #     cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
    "# #     text_counts= cv.fit_transform(row['tweet'])\n",
    "\n",
    "#     list_of_tweets.append(text_counts)\n",
    "# list_of_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600000x790498 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 19080720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1600000x684358 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18986995 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(data_df['tweet'])\n",
    "text_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 684358)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    text_counts, data_df['sentiment'], test_size=0.05, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-958faf15f587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy: 0.7693\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# #Import scikit-learn metrics module for accuracy calculation\n",
    "# from sklearn import metrics\n",
    "# # Model Generation Using Multinomial Naive Bayes\n",
    "# clf = MultinomialNB(alpha=2).fit(X_train, y_train)\n",
    "# predicted= clf.predict(X_test)\n",
    "# print(\"MultinomialNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Accuracy: 0.7713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Generation Using Bernoulli Naive Bayes -- used for boolean\n",
    "clf = BernoulliNB(alpha=4).fit(X_train, y_train)\n",
    "predicted= clf.predict(X_test)\n",
    "print(\"BernoulliNB Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_train)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
