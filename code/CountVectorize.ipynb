{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vector and count the words in tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import func, inspect\n",
    "from sqlalchemy import Table, Column, Integer, String, Float, DateTime, MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine for the  database\n",
    "\n",
    "engine = create_engine(\"sqlite:///../data/data.sqlite\", echo=False)\n",
    "conn = engine.connect()\n",
    "\n",
    "# Reflect Database into ORM classes\n",
    "Base = automap_base()\n",
    "Base.prepare(engine, reflect=True)\n",
    "meta = MetaData()\n",
    "\n",
    "tweets = Table(\n",
    "   'tweets', meta, \n",
    "    Column('source',String), \n",
    "    Column('text', String), \n",
    "    Column('created_at', DateTime),\n",
    "    Column('retweet_count', Integer),\n",
    "    Column('favorite_count', Integer),\n",
    "    Column('id_str', Integer, primary_key = True)\n",
    ")\n",
    "\n",
    "no_retweets = Table(\n",
    "   'no_retweets', meta, \n",
    "    Column('source',String), \n",
    "    Column('text', String), \n",
    "    Column('created_at', DateTime),\n",
    "    Column('retweet_count', Integer),\n",
    "    Column('favorite_count', Integer),\n",
    "    Column('id_str', Integer, primary_key = True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- select column 'text' from the tweets table - this has no retweets\n",
    "tweets_text_data = pd.read_sql('SELECT TEXT FROM TWEETS', conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_text_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Count Vectorizer\n",
    "#vectorizer = CountVectorizer( lowercase=True, token_pattern=r'\\b[^\\d\\W]+\\b', stop_words='english')\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "my_additional_stop_words = ['https','rt']\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(my_additional_stop_words)\n",
    "vectorizer = CountVectorizer( lowercase=True, stop_words=stop_words)\n",
    "\n",
    "vector_text = tweets\n",
    "\n",
    "# To actually create the vectorizer, we simply need to call fit on the text\n",
    "# data that we wish to fix\n",
    "cv_fit = vectorizer.fit_transform(vector_text)\n",
    "\n",
    "# Now, we can inspect how our vectorizer vectorized the text\n",
    "# This will print out a list of words used, and their index in the vectors\n",
    "# print('Vocabulary: ')\n",
    "# print(vectorizer.vocabulary_)\n",
    "\n",
    "# # If we would like to actually create a vector, we can do so by passing the\n",
    "# # text into the vectorizer to get back counts\n",
    "# vector = vectorizer.transform(vector_text)\n",
    "\n",
    "# # Our final vector:\n",
    "# print('Full vector: ')\n",
    "# print(vector.toarray())\n",
    "\n",
    "# # Or if we wanted to get the vector for one word:\n",
    "# print('Hot vector: ')\n",
    "# print(vectorizer.transform(['hot']).toarray())\n",
    "\n",
    "# # Or if we wanted to get multiple vectors at once to build matrices\n",
    "# print('Hot and one: ')\n",
    "# print(vectorizer.transform(['hot', 'one']).toarray())\n",
    "\n",
    "# # We could also do the whole thing at once with the fit_transform method:\n",
    "# print('One swoop:')\n",
    "# new_text = ['Today is the day that I do the thing today, today']\n",
    "# new_vectorizer = CountVectorizer()\n",
    "# print(new_vectorizer.fit_transform(new_text).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_counts = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>cnt_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21819</th>\n",
       "      <td>realdonaldtrump</td>\n",
       "      <td>4157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11616</th>\n",
       "      <td>great</td>\n",
       "      <td>4067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27046</th>\n",
       "      <td>trump</td>\n",
       "      <td>3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>amp</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20791</th>\n",
       "      <td>president</td>\n",
       "      <td>2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26219</th>\n",
       "      <td>thank</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20063</th>\n",
       "      <td>people</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14767</th>\n",
       "      <td>just</td>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>america</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>country</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18547</th>\n",
       "      <td>new</td>\n",
       "      <td>1232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>big</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16716</th>\n",
       "      <td>make</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>http</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656</th>\n",
       "      <td>democrats</td>\n",
       "      <td>1061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26544</th>\n",
       "      <td>time</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18564</th>\n",
       "      <td>news</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26659</th>\n",
       "      <td>today</td>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8378</th>\n",
       "      <td>donald</td>\n",
       "      <td>909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12370</th>\n",
       "      <td>hillary</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16073</th>\n",
       "      <td>like</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>don</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11408</th>\n",
       "      <td>good</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28504</th>\n",
       "      <td>vote</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>fake</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>border</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28762</th>\n",
       "      <td>want</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27050</th>\n",
       "      <td>trump2016</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11376</th>\n",
       "      <td>going</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17191</th>\n",
       "      <td>media</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>hxwak3iypk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>hxvyydcnw5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>hxusbgfmf2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>hxduwsoelz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>hxdfy0mjvw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>hxcptlruvo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>hx87ytsqxs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854</th>\n",
       "      <td>hysaqob6gw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12856</th>\n",
       "      <td>hyun</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12858</th>\n",
       "      <td>hyxxfcfauh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12870</th>\n",
       "      <td>i1k4nj1gvu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12879</th>\n",
       "      <td>i4vz1mrdbk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12878</th>\n",
       "      <td>i4f8xixora</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12877</th>\n",
       "      <td>i3tpdjtuua</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12876</th>\n",
       "      <td>i3lo117svh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12875</th>\n",
       "      <td>i2wqzb5n8p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12874</th>\n",
       "      <td>i2cjsqikgn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12873</th>\n",
       "      <td>i2cjsqalyl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12871</th>\n",
       "      <td>i1lmmcyk3l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12869</th>\n",
       "      <td>i1eauftksf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12859</th>\n",
       "      <td>hz2q9utfnf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12868</th>\n",
       "      <td>i0zjo2szkk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12867</th>\n",
       "      <td>i0gvcqltko</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12865</th>\n",
       "      <td>hzzdqy5qqv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12864</th>\n",
       "      <td>hzlkplebet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12863</th>\n",
       "      <td>hze3fuqkdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12862</th>\n",
       "      <td>hzcmp5csjc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12861</th>\n",
       "      <td>hzbqw35onm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12860</th>\n",
       "      <td>hz6fwlid3l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30550</th>\n",
       "      <td>한국전쟁</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30551 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  cnt_word\n",
       "21819  realdonaldtrump      4157\n",
       "11616            great      4067\n",
       "27046            trump      3229\n",
       "2693               amp      2790\n",
       "20791        president      2055\n",
       "...                ...       ...\n",
       "12863       hze3fuqkdf         1\n",
       "12862       hzcmp5csjc         1\n",
       "12861       hzbqw35onm         1\n",
       "12860       hz6fwlid3l         1\n",
       "30550             한국전쟁         1\n",
       "\n",
       "[30551 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_count_df = pd.DataFrame({\"word\": feature_names, \"cnt_word\": feature_counts})\n",
    "final_count_df.sort_values(by='cnt_word', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_count_df.to_csv('../data/final_word_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pandas] *",
   "language": "python",
   "name": "conda-env-pandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
